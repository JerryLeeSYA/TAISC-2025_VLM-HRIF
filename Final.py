#!/usr/bin/env python3
"""
æµç¨‹: è¨“ç·´ -> é æ¸¬ -> GMMè½‰æ› -> æ­£è¦åŒ– -> ç”¢å‡ºæäº¤æª”æ¡ˆ
æ¨¡å‹: ViT-Large-336, åœ–åƒå°ºå¯¸: 336x336
"""

import os, platform
import random
import warnings
import numpy as np
import pandas as pd
from PIL import Image
from typing import Dict, List
from pathlib import Path
from datetime import datetime

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torch.optim import AdamW
from huggingface_hub import snapshot_download

# å®‰å…¨å°å…¥æ¨¡çµ„
try:
    from transformers import CLIPModel, CLIPProcessor
    CLIP_AVAILABLE = True
    print("âœ… CLIPæ¨¡å‹å¯ç”¨")
except ImportError:
    CLIP_AVAILABLE = False
    print("âŒ CLIPæ¨¡å‹ä¸å¯ç”¨")

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score
from sklearn.mixture import GaussianMixture # æ–°å¢ GMM å°å…¥
from sklearn.exceptions import ConvergenceWarning
from tqdm import tqdm

warnings.filterwarnings("ignore")

class Config:
    """é…ç½®é¡"""
    
    def _find_available_model(self):
        target_root = Path("./models")
        target_root.mkdir(exist_ok=True)
        local_model_path_str = "./models/openai--clip-vit-large-patch14-336"
        self.local_model_paths = {"clip-large": local_model_path_str}
        
        search_dirs = [local_model_path_str, str(target_root)]
        for base in search_dirs:
            for root, _, files in os.walk(base):
                if "config.json" in files:
                    print(f"âœ… æ‰¾åˆ°æœ¬åœ°æ¨¡å‹: {root}")
                    return root

        repo_id = "openai/clip-vit-large-patch14-336"
        is_windows = platform.system().lower() == "windows"
        if is_windows:
            os.environ["HF_HUB_DISABLE_SYMLINKS_WINDOWS"] = "1"

        try:
            print(f"âš ï¸ æœ¬åœ°æœªæ‰¾åˆ°ï¼Œé–‹å§‹ä¸‹è¼‰ {repo_id} â†’ {target_root} â€¦")
            local_path = snapshot_download(
                repo_id=repo_id,
                local_dir=target_root / repo_id.replace("/", "--"),
                local_dir_use_symlinks=False,
                resume_download=True
            )
            print(f"âœ… ä¸‹è¼‰å®Œæˆï¼Œå·²å­˜æ”¾æ–¼: {local_path}")
            return local_path
        except Exception as e:
            print(f"âŒ ä¸‹è¼‰å¤±æ•—: {e}")
        return None
    
    def __init__(self):
        # --- æ¨¡å‹ ---
        self.model_name = self._find_available_model()
        self.model_type = "clip"
        
        # --- æ ¸å¿ƒè¨“ç·´åƒæ•¸ ---
        self.danger_class_weight = 1.5
        self.use_class_weights = True
        self.prediction_threshold = 0.35
        self.image_size = 336
        self.max_length = 77
        self.batch_size = 4
        self.learning_rate = 1e-5
        self.weight_decay = 0.001
        self.max_grad_norm = 0.05
        self.num_epochs = 1
        self.early_stopping_patience = 8
        self.monitor_metric = "val_f1"
        self.min_delta = 0.01
        
        # --- è·¯å¾‘èˆ‡ç’°å¢ƒ ---
        self.data_path = "./AVA Dataset"
        self.output_dir = "./outputs"
        self.checkpoint_dir = "./checkpoints"
        self.random_seed = 42
        self.train_split = 0.8
        self.val_split = 0.2
        self.save_best_only = True
        
        # --- æ‰“å°é…ç½® ---
        print("\n" + "="*50)
        print("ğŸ¯ é…ç½®å·²é–å®š")
        print(f"  - æ¨¡å‹åç¨±: {self.model_name}")
        print(f"  - æ•¸æ“šè·¯å¾‘: {self.data_path}")
        print(f"  - å­¸ç¿’ç‡: {self.learning_rate}")
        print(f"  - æ‰¹æ¬¡å¤§å°: {self.batch_size}")
        print(f"  - è¨“ç·´è¼ªæ•¸: {self.num_epochs}")
        print("="*50 + "\n")


class TAISCDataset(Dataset):
    """TAISCæ•¸æ“šé›†é¡"""
    def __init__(self, data_path: str, split: str = "train", processor=None, config=None):
        self.data_path = Path(data_path)
        self.split = split
        self.processor = processor
        self.config = config
        
        self.danger_prompts = ["A dash-cam frame where a crash is about to occur","Vehicle cutting in sharply, high risk of collision","Car hard-braking, following distance almost zero","Pedestrian suddenly entering the driving lane","Bike crossing ahead, imminent impact expected","Oncoming traffic encroaching the ego lane","Obstacle on road, driver must swerve within seconds","Red-light runner entering intersection, crash likely","Ego vehicle tailgating, no safe braking margin","Rain-soaked road and skid about to happen","Vehicle drifting across lane markings toward us","Blind curve with blocked sight, head-on risk","Truck merging without gap, emergency response needed","High speed plus stalled car ahead, unavoidable danger","Crowd jaywalking, collision risk very high","Stop-and-go traffic, abrupt rear-end threat","Sharp turn taken too fast, loss of control imminent","Road debris directly in driving path, impact imminent","Driver texting, vehicle veering off lane","Critical split-second before traffic accident"]
        self.safety_prompts = ["Calm highway driving with ample following distance","Urban street scene, vehicles obeying traffic rules","Smooth traffic flow, no immediate hazards detected","Ego vehicle centered in lane, speed appropriate","Clear weather and empty road ahead","Stop line respected, pedestrians safely crossing","Cruise control on straight freeway, stable situation","All vehicles maintaining lane discipline and gaps","Green-light passage with no conflicting traffic","Daytime driving, excellent visibility, no risks","Motorists signalling properly before lane change","Roundabout navigation executed safely","Low speed residential area, no obstacles present","Car ahead braking gently, safe distance kept","Driver scanning mirrors, environment under control","No pedestrians or cyclists near path of travel","Dry pavement, tyres gripping well, stable handling","Night driving with correct headlight use, clear road","Ego car waiting patiently at crosswalk, safe","Routine commute traffic, normal conditions"]
        self.neutral_prompts = ["Describe the traffic situation in this frame","What potential hazards can be seen here?","Analyse the driverâ€™s required reaction","Explain the safety level of this road scene","Summarise the dynamic elements in view","Classify whether emergency action is needed"]
        
        self.samples = self._load_samples()
        print(f"è¼‰å…¥ {split} æ•¸æ“š: {len(self.samples)} å€‹æ¨£æœ¬")

    def _load_samples(self) -> List[Dict]:
        samples = []
        data_root = self.data_path
        
        if self.split in ["train", "val"]:
            for scene in ["road", "freeway"]:
                csv_path = data_root / f"{scene}_train.csv"
                if not csv_path.exists(): continue
                
                df = pd.read_csv(csv_path)
                scene_dir = data_root / scene / "train"
                
                for _, row in df.iterrows():
                    sequence_path = scene_dir / row['file_name']
                    if not sequence_path.exists(): continue
                    
                    image_files = sorted(list(sequence_path.glob('*.jpg')) + list(sequence_path.glob('*.png')))
                    if image_files:
                        samples.append({
                            'image_path': str(image_files[0]), 'file_name': row['file_name'],
                            'scene': scene, 'risk': int(row['risk'])
                        })
        elif self.split == "test":
            for scene in ["road", "freeway"]:
                scene_dir = data_root / scene / "test"
                if not scene_dir.exists(): continue
                
                for sequence_path in scene_dir.iterdir():
                    if not sequence_path.is_dir(): continue
                    image_files = sorted(list(sequence_path.glob('*.jpg')) + list(sequence_path.glob('*.png')))
                    if image_files:
                        samples.append({
                            'image_path': str(image_files[0]), 'file_name': sequence_path.name,
                            'scene': scene, 'risk': 0
                        })
        return samples
    
    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        sample = self.samples[idx]
        try:
            image = Image.open(sample['image_path']).convert('RGB').resize(
                (self.config.image_size, self.config.image_size), Image.Resampling.LANCZOS)
            
            risk_label = sample['risk']
            rand_val = random.random()

            if risk_label == 1:
                if rand_val < 0.8: prompt = random.choice(self.danger_prompts)
                elif rand_val < 0.9: prompt = random.choice(self.safety_prompts)
                else: prompt = random.choice(self.neutral_prompts)
            else:
                if rand_val < 0.8: prompt = random.choice(self.safety_prompts)
                elif rand_val < 0.9: prompt = random.choice(self.danger_prompts)
                else: prompt = random.choice(self.neutral_prompts)
            
            inputs = self.processor(
                text=prompt, images=image, return_tensors="pt", padding="max_length",
                truncation=True, max_length=self.config.max_length
            )
            for key in inputs.keys():
                if isinstance(inputs[key], torch.Tensor):
                    inputs[key] = inputs[key].squeeze(0)
            
            return {
                'inputs': inputs, 'label': torch.tensor(sample['risk'], dtype=torch.long),
                'file_name': sample['file_name'], 'scene': sample['scene']
            }
        except Exception as e:
            print(f"è™•ç†æ¨£æœ¬ {sample['file_name']} æ™‚å‡ºéŒ¯: {e}")
            return self._get_dummy_sample()

    def _create_dummy_inputs(self):
        return {
            'pixel_values': torch.randn(3, self.config.image_size, self.config.image_size),
            'input_ids': torch.randint(0, 1000, (self.config.max_length,)),
            'attention_mask': torch.ones(self.config.max_length)
        }
        
    def _get_dummy_sample(self):
        return {
            'inputs': self._create_dummy_inputs(), 'label': torch.tensor(0, dtype=torch.long),
            'file_name': 'dummy', 'scene': 'road'
        }

class AccidentPredictionVLM(nn.Module):
    """äº‹æ•…é æ¸¬VLMæ¨¡å‹"""
    def __init__(self, config):
        super().__init__()
        self.config = config
        self.vlm_model = CLIPModel.from_pretrained(config.model_name, local_files_only=True)
        self.feature_dim = self.vlm_model.config.projection_dim
        
        self.classifier = nn.Sequential(
            nn.Linear(self.feature_dim, 512),
            nn.ReLU(inplace=True),
            nn.Linear(512, 1)
        )
        self._initialize_weights()

    def _initialize_weights(self):
        for module in self.classifier.modules():
            if isinstance(module, nn.Linear):
                nn.init.xavier_uniform_(module.weight)
                if module.bias is not None:
                    nn.init.constant_(module.bias, 0)
    
    def forward(self, inputs):
        features = self.vlm_model(**inputs).image_embeds
        if self.training:
            features = F.dropout(features, p=0.3, training=True)
        return self.classifier(features).squeeze(1)

class Trainer:
    """è¨“ç·´å™¨é¡"""
    def __init__(self, config: Config):
        self.config = config
        self.setup_environment()
        self.setup_model_and_data()
        self.setup_training()
        
    def setup_environment(self):
        self.set_seed(self.config.random_seed)
        os.makedirs(self.config.output_dir, exist_ok=True)
        os.makedirs(self.config.checkpoint_dir, exist_ok=True)
        
        if torch.cuda.is_available():
            self.device = torch.device("cuda")
            print(f"âœ… ä½¿ç”¨GPU: {torch.cuda.get_device_name()}")
        else:
            self.device = torch.device("cpu")
            print("âœ… ä½¿ç”¨CPU")

    def set_seed(self, seed):
        random.seed(seed)
        np.random.seed(seed)
        torch.manual_seed(seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed_all(seed)

    def setup_model_and_data(self):
        self.processor = CLIPProcessor.from_pretrained(self.config.model_name, local_files_only=True)
        
        full_dataset = TAISCDataset(self.config.data_path, "train", self.processor, self.config)
        if len(full_dataset) == 0:
            raise ValueError(f"æ•¸æ“šé›†ç‚ºç©ºï¼è«‹æª¢æŸ¥è·¯å¾‘: {self.config.data_path}")
        
        train_samples, val_samples = train_test_split(
            full_dataset.samples, test_size=self.config.val_split,
            random_state=self.config.random_seed, stratify=[s['risk'] for s in full_dataset.samples]
        )
        
        train_dataset = TAISCDataset(self.config.data_path, "train", self.processor, self.config)
        train_dataset.samples = train_samples
        
        val_dataset = TAISCDataset(self.config.data_path, "val", self.processor, self.config)
        val_dataset.samples = val_samples
        
        self.train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True, num_workers=0, collate_fn=self.collate_fn)
        self.val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size, shuffle=False, num_workers=0, collate_fn=self.collate_fn)
        
        self.model = AccidentPredictionVLM(self.config).to(self.device)

    def collate_fn(self, batch):
        batch = [b for b in batch if b is not None]
        if not batch: return None
        
        inputs_list = [item['inputs'] for item in batch]
        labels = torch.stack([item['label'] for item in batch])
        file_names = [item['file_name'] for item in batch]
        
        batch_inputs = {}
        for key in inputs_list[0].keys():
            batch_inputs[key] = torch.stack([inp[key] for inp in inputs_list])
            
        return {'inputs': batch_inputs, 'labels': labels, 'file_names': file_names}
    
    def setup_training(self):
        labels = [s['risk'] for s in self.train_loader.dataset.samples]
        pos_w_value = (len(labels) - sum(labels)) / sum(labels) if sum(labels) > 0 else 1.0
        pos_w = torch.tensor([pos_w_value], device=self.device)
        self.criterion = nn.BCEWithLogitsLoss(pos_weight=pos_w)
        
        for param in self.model.vlm_model.parameters():
            param.requires_grad = False
        
        unfreeze_layers = ["visual.transformer.resblocks.10", "visual.transformer.resblocks.11", "visual.ln_post"]
        for name, param in self.model.vlm_model.named_parameters():
            if any(layer_name in name for layer_name in unfreeze_layers):
                param.requires_grad = True
        
        for param in self.model.classifier.parameters():
            param.requires_grad = True
        
        classifier_params = {'params': self.model.classifier.parameters(), 'lr': 0.000777}
        vision_params_gen = (p for n, p in self.model.vlm_model.named_parameters() if p.requires_grad)
        vision_finetune_params = {'params': vision_params_gen, 'lr': 1e-5}
        
        self.optimizer = AdamW([classifier_params, vision_finetune_params], weight_decay=self.config.weight_decay)
        self.scheduler = None # ä¸ä½¿ç”¨èª¿åº¦å™¨
        
        self.best_metric = 0.0
        self.patience_counter = 0

    def train_epoch(self, epoch):
        self.model.train()
        total_loss, all_labels, all_predictions = 0.0, [], []
        progress_bar = tqdm(self.train_loader, desc=f"Epoch {epoch+1}/{self.config.num_epochs}", leave=False)
        
        for batch in progress_bar:
            if batch is None: continue
            inputs = {k: v.to(self.device) for k, v in batch['inputs'].items()}
            labels = batch['labels'].to(self.device)
            
            self.optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = self.criterion(outputs, labels.float())
            
            if torch.isnan(loss): continue
            
            loss.backward()
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=self.config.max_grad_norm)
            self.optimizer.step()
            
            total_loss += loss.item()
            probabilities = torch.sigmoid(outputs)
            predictions = (probabilities > self.config.prediction_threshold).long()
            all_labels.extend(labels.cpu().numpy())
            all_predictions.extend(predictions.cpu().detach().numpy())
            progress_bar.set_postfix(loss=f"{loss.item():.4f}")
            
        if not all_labels: return 0.0, 0.0, 0.0
        avg_loss = total_loss / len(self.train_loader)
        train_acc = accuracy_score(all_labels, all_predictions)
        train_f1 = f1_score(all_labels, all_predictions, zero_division=0)
        return avg_loss, train_acc, train_f1
    
    def validate(self):
        self.model.eval()
        total_loss, all_labels, all_probabilities = 0, [], []
        with torch.no_grad():
            for batch in tqdm(self.val_loader, desc="Validating", leave=False):
                if batch is None: continue
                inputs = {k: v.to(self.device) for k, v in batch['inputs'].items()}
                labels = batch['labels'].to(self.device)
                outputs = self.model(inputs)
                loss = self.criterion(outputs, labels.float())
                total_loss += loss.item()
                all_labels.extend(labels.cpu().numpy())
                all_probabilities.extend(torch.sigmoid(outputs).cpu().numpy())
        
        if not all_probabilities: return float('inf'), 0.0, 0.0, 0.5
        
        val_loss = total_loss / len(self.val_loader)
        val_auc = roc_auc_score(all_labels, all_probabilities) if len(set(all_labels)) > 1 else 0.5
        
        best_f1, best_acc, best_threshold = 0, 0, 0.5
        for threshold in np.arange(0.3, 0.7, 0.05):
            predictions = (np.array(all_probabilities) > threshold).astype(int)
            f1 = f1_score(all_labels, predictions, zero_division=0)
            if f1 > best_f1:
                best_f1, best_acc, best_threshold = f1, accuracy_score(all_labels, predictions), threshold
                
        self.config.prediction_threshold = best_threshold
        return val_loss, best_acc, best_f1, val_auc
        
    def save_checkpoint(self, epoch, is_best=False):
        state = {'epoch': epoch, 'model_state_dict': self.model.state_dict(),
                 'optimizer_state_dict': self.optimizer.state_dict(), 'best_metric': self.best_metric}
        if is_best:
            torch.save(state, os.path.join(self.config.checkpoint_dir, 'best_model.pth'))
            print(f"ğŸ’¾ æ–°æœ€ä½³æ¨¡å‹å·²ä¿å­˜ (ç›£æ§æŒ‡æ¨™: {self.best_metric:.4f})")
    
    def train(self):
        for epoch in range(self.config.num_epochs):
            train_loss, train_acc, train_f1 = self.train_epoch(epoch)
            val_loss, val_acc, val_f1, val_auc = self.validate()
            
            print(f"Epoch {epoch+1}/{self.config.num_epochs} | "
                  f"Train: Loss={train_loss:.4f} Acc={train_acc:.4f} F1={train_f1:.4f} | "
                  f"Val: Loss={val_loss:.4f} Acc={val_acc:.4f} F1={val_f1:.4f} AUC={val_auc:.4f}")
            
            current_metric = locals()[self.config.monitor_metric]
            is_best = current_metric > self.best_metric
            if is_best:
                self.best_metric = current_metric
                self.patience_counter = 0
            else:
                self.patience_counter += 1
            
            self.save_checkpoint(epoch, is_best)
            if self.patience_counter >= self.config.early_stopping_patience:
                print(f"ğŸ›‘ æ—©åœï¼å·²é€£çºŒ {self.config.early_stopping_patience} å€‹ epoch ç„¡æ”¹å–„ã€‚")
                break
        print(f"\nğŸ‰ è¨“ç·´å®Œæˆï¼æœ€ä½³ {self.config.monitor_metric}: {self.best_metric:.4f}")

class Predictor:
    """é æ¸¬å™¨é¡"""
    def __init__(self, config: Config, checkpoint_path: str):
        self.config = config
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model = AccidentPredictionVLM(self.config)
        checkpoint = torch.load(checkpoint_path, map_location=self.device, weights_only=False)
        self.model.load_state_dict(checkpoint['model_state_dict']) # <--- å¾å­—å…¸ä¸­å–å‡ºæ¬Šé‡
        self.model.to(self.device).eval()
        self.processor = CLIPProcessor.from_pretrained(config.model_name, local_files_only=True)
        print(f"âœ… é æ¸¬å™¨è¼‰å…¥æ¨¡å‹: {checkpoint_path}")

    def collate_fn(self, batch):
        batch = [b for b in batch if b is not None]
        if not batch: return None
        inputs_list = [item['inputs'] for item in batch]
        file_names = [item['file_name'] for item in batch]
        batch_inputs = {key: torch.stack([inp[key] for inp in inputs_list]) for key in inputs_list[0]}
        return {'inputs': batch_inputs, 'file_names': file_names}

    def predict_test_data(self) -> pd.DataFrame:
        test_dataset = TAISCDataset(self.config.data_path, "test", self.processor, self.config)
        if len(test_dataset) == 0: return pd.DataFrame()
        
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size, shuffle=False, num_workers=0, collate_fn=self.collate_fn)
        predictions = {}
        with torch.no_grad():
            for batch in tqdm(test_loader, desc="Predicting"):
                if batch is None: continue
                inputs = {k: v.to(self.device) for k, v in batch['inputs'].items()}
                outputs = self.model(inputs)
                probabilities = torch.sigmoid(outputs).cpu().numpy()
                for file_name, prob in zip(batch['file_names'], probabilities):
                    predictions[file_name] = float(prob)
        
        submission_df = pd.DataFrame(list(predictions.items()), columns=['file_name', 'risk'])
        raw_output_path = os.path.join(self.config.output_dir, 'submission_raw.csv')
        submission_df.to_csv(raw_output_path, index=False)
        print(f"âœ… åŸå§‹é æ¸¬å·²ä¿å­˜è‡³: {raw_output_path}")
        return submission_df

# ===================================================================
# å¾Œè™•ç†å‡½æ•¸
# ===================================================================
def normalize_scores(scores: np.ndarray) -> np.ndarray:
    """å°‡åˆ†æ•¸é€²è¡ŒMin-Maxæ­£è¦åŒ–åˆ°[0, 1]å€é–“"""
    print("ğŸ“ æ­¥é©Ÿ 3a: åŸ·è¡ŒMin-Maxæ­£è¦åŒ–...")
    min_val, max_val = scores.min(), scores.max()
    if max_val == min_val:
        return np.full_like(scores, 0.5) # å¦‚æœæ‰€æœ‰å€¼éƒ½ä¸€æ¨£ï¼Œè¿”å›0.5
    normalized = (scores - min_val) / (max_val - min_val)
    return normalized

def find_gmm_threshold(scores: np.ndarray, config: Config) -> float | None:
    """
    ä½¿ç”¨ 2-component Gaussian Mixture æ‰¾æ±ºç­–é‚Šç•Œï¼ˆposterior=0.5ï¼‰ã€‚
    """
    scores_reshaped = scores.reshape(-1, 1)
    with warnings.catch_warnings():
        warnings.filterwarnings("ignore", category=ConvergenceWarning)
        gmm = GaussianMixture(n_components=2, random_state=config.random_seed)
        gmm.fit(scores_reshaped)
    
    means = gmm.means_.flatten()
    # å¦‚æœå…©å€‹åˆ†ä½ˆçš„ä¸­å¿ƒé»å¤ªæ¥è¿‘ï¼Œè¦–ç‚ºå–®å³°ï¼ŒGMMä¸é©ç”¨
    if abs(means[0] - means[1]) < 1e-3:
        return None

    # è§£ w1*N1 = w2*N2 çš„äºŒæ¬¡æ–¹ç¨‹å¼ï¼Œæ‰¾åˆ°å…©é«˜æ–¯åˆ†ä½ˆçš„äº¤é»
    m1, m2 = means
    v1, v2 = gmm.covariances_.flatten()
    w1, w2 = gmm.weights_
    
    a = 1/(2*v1) - 1/(2*v2)
    b = m2/(v2) - m1/(v1)
    c = m1**2/(2*v1) - m2**2/(2*v2) + np.log((w2*np.sqrt(v1))/(w1*np.sqrt(v2)))
    
    # å¿½ç•¥è™›æ ¹ï¼Œé¸æ“‡è½åœ¨åˆ†æ•¸å€é–“å…§çš„å¯¦æ ¹
    roots = np.roots([a, b, c])
    real_roots = [r.real for r in roots if r.imag == 0]
    valid_thresholds = [t for t in real_roots if scores.min() < t < scores.max()]
    
    return valid_thresholds[0] if valid_thresholds else None

def find_best_threshold(scores: np.ndarray, config: Config, fallback_percentile=80) -> tuple[float, str]:
    """
    å„ªå…ˆå˜—è©¦GMMå°‹æ‰¾é–¾å€¼ï¼Œè‹¥å¤±æ•—å‰‡é€€å›ä½¿ç”¨ç™¾åˆ†ä½æ³•ã€‚
    è¿”å› (é–¾å€¼, ä½¿ç”¨çš„æ–¹æ³•åç¨±)ã€‚
    """
    # å˜—è©¦ GMM
    gmm_thr = find_gmm_threshold(scores, config)
    if gmm_thr is not None:
        return gmm_thr, "GMM"
    
    # GMM å¤±æ•—ï¼Œä½¿ç”¨ç™¾åˆ†ä½æ³•
    percentile_thr = np.percentile(scores, fallback_percentile)
    return percentile_thr, f"Percentile_{fallback_percentile}"

# ===================================================================
# ä¿®æ”¹å¾Œçš„ä¸»å‡½æ•¸
# ===================================================================

def main():
    """ä¸»å‡½æ•¸ï¼šè¨“ç·´ -> é æ¸¬ -> æ­£è¦åŒ– -> GMMé–¾å€¼ -> äºŒå…ƒåŒ– -> ç”¢å‡º"""
    try:
        # --- æ­¥é©Ÿ 0: åˆå§‹åŒ–é…ç½® ---
        config = Config()

        # --- æ­¥é©Ÿ 1: è¨“ç·´æ¨¡å‹ ---
        print("\n--- æ­¥é©Ÿ 1: é–‹å§‹è¨“ç·´ ---")
        trainer = Trainer(config)
        trainer.train()

        # --- æ­¥é©Ÿ 2: ä½¿ç”¨æœ€ä½³æ¨¡å‹é€²è¡Œé æ¸¬ ---
        print("\n--- æ­¥é©Ÿ 2: ä½¿ç”¨æœ€ä½³æ¨¡å‹é€²è¡Œé æ¸¬ ---")
        best_model_path = os.path.join(config.checkpoint_dir, 'best_model.pth')
        if not os.path.exists(best_model_path):
            raise FileNotFoundError(f"è¨“ç·´çµæŸä½†æ‰¾ä¸åˆ°æœ€ä½³æ¨¡å‹æ–‡ä»¶: {best_model_path}")
            
        predictor = Predictor(config, best_model_path)
        submission_df = predictor.predict_test_data()

        if submission_df.empty:
            print("âŒ é æ¸¬çµæœç‚ºç©ºï¼Œç„¡æ³•é€²è¡Œå¾Œè™•ç†ã€‚")
            return

        # --- æ­¥é©Ÿ 3: å¾Œè™•ç† (æ­£è¦åŒ– -> GMMé–¾å€¼ -> äºŒå…ƒåŒ–) ---
        print("\n--- æ­¥é©Ÿ 3: é€²è¡Œå¾Œè™•ç† ---")
        
        # æ­¥é©Ÿ 3a: å°æ‰€æœ‰é¢¨éšªåˆ†æ•¸é€²è¡Œæ­£è¦åŒ–
        raw_scores = submission_df['risk'].values
        submission_df['normalized_risk'] = normalize_scores(raw_scores)
        
        # æ­¥é©Ÿ 3b: åˆ†å ´æ™¯è¨ˆç®—GMMé–¾å€¼
        print("ğŸ”® æ­¥é©Ÿ 3b: åˆ†å ´æ™¯è¨ˆç®—GMMé–¾å€¼...")
        submission_df['group'] = submission_df['file_name'].apply(
            lambda x: 'road' if x.startswith('road') else 'freeway')
            
        thresholds = {}
        for group in ['road', 'freeway']:
            group_scores = submission_df[submission_df['group'] == group]['normalized_risk'].values
            if len(group_scores) > 0:
                thr, method = find_best_threshold(group_scores, config)
                thresholds[group] = thr
                print(f"  - {group.upper():7s} -> æ–¹æ³•: {method:12s} | é–¾å€¼: {thr:.4f}")
            else:
                thresholds[group] = 0.5 # å¦‚æœæ²’æœ‰è©²å ´æ™¯çš„æ•¸æ“šï¼Œé è¨­ä¸€å€‹é–¾å€¼
        
        # æ­¥é©Ÿ 3c: æ‡‰ç”¨é–¾å€¼é€²è¡ŒäºŒå…ƒåŒ–
        print("ğŸš¦ æ­¥é©Ÿ 3c: æ‡‰ç”¨é–¾å€¼ç”Ÿæˆ 0/1 æ¨™ç±¤...")
        submission_df['risk'] = submission_df.apply(
            lambda row: 1 if row['normalized_risk'] >= thresholds[row['group']] else 0,
            axis=1
        )

        # --- æ­¥é©Ÿ 4: ç”¢ç”Ÿæœ€çµ‚æäº¤æª”æ¡ˆ ---
        print("\n--- æ­¥é©Ÿ 4: ç”¢ç”Ÿæœ€çµ‚æäº¤æª”æ¡ˆ ---")
        final_submission_df = submission_df[['file_name', 'risk']]
        
        final_output_path = os.path.join(config.output_dir, 'submission_final.csv')
        final_submission_df.to_csv(final_output_path, index=False)
        
        print("\n" + "="*60)
        print("ğŸ‰ğŸ‰ğŸ‰ æµç¨‹åŸ·è¡Œå®Œç•¢ï¼ğŸ‰ğŸ‰ğŸ‰")
        print(f"æœ€çµ‚æäº¤æª”æ¡ˆå·²ä¿å­˜è‡³: {final_output_path}")
        print("æœ€çµ‚é æ¸¬åˆ†ä½ˆ:")
        print(final_submission_df['risk'].value_counts().rename(index={0: 'ä½é¢¨éšª (0)', 1: 'é«˜é¢¨éšª (1)'}))
        print("="*60)

    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç¨‹åºè¢«ç”¨æˆ¶ä¸­æ–·ã€‚")
    except Exception as e:
        print(f"\nâŒ åŸ·è¡Œéç¨‹ä¸­å‡ºç¾åš´é‡éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()